{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb911b3",
   "metadata": {},
   "source": [
    "# Predicting Household Occupancy using Motion Sensor Data\n",
    "\n",
    "Process of building a model to predict whether a household is single or multiple occupancy using motion sensor data.\n",
    "The steps include data loading, feature engineering, handling class imbalance, model training, and evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373c8869",
   "metadata": {},
   "source": [
    "# 1. Importing Necessary Libraries\n",
    "\n",
    "Importing the required libraries for data processing, machine learning, and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9818fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d95bcf",
   "metadata": {},
   "source": [
    "# 2. Loading Data and Data Preprocessing\n",
    "\n",
    "Connecting to the SQLite database and load the data from the `homes` and `motion` tables.\n",
    "Converting the `datetime` column in the motion data to pandas datetime objects for easier manipulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2251a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = sqlite3.connect(r\"C:\\Users\\Prashanth\\Downloads\\data.db\")\n",
    "\n",
    "# Load the homes data\n",
    "homes_df = pd.read_sql_query(\"SELECT * FROM homes\", conn)\n",
    "\n",
    "# Load the motion data\n",
    "motion_df = pd.read_sql_query(\"SELECT * FROM motion\", conn)\n",
    "\n",
    "# Convert datetime to pandas datetime\n",
    "motion_df['datetime'] = pd.to_datetime(motion_df['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb07c2",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering\n",
    "\n",
    "Creatng new features from the motion data to capture different aspects of household activity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9c8d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced feature engineering\n",
    "def create_features(group):\n",
    "    morning = group['datetime'].dt.hour.between(6, 12).sum()\n",
    "    afternoon = group['datetime'].dt.hour.between(12, 18).sum()\n",
    "    evening = group['datetime'].dt.hour.between(18, 24).sum()\n",
    "    night = group['datetime'].dt.hour.between(0, 6).sum()\n",
    "    \n",
    "    return pd.Series({\n",
    "        'motion_count': group['id'].count(),\n",
    "        'time_range_hours': (group['datetime'].max() - group['datetime'].min()).total_seconds() / 3600,\n",
    "        'unique_locations': group['location'].nunique(),\n",
    "        'activity_hours': group['datetime'].dt.hour.nunique(),\n",
    "        'events_per_hour': group['id'].count() / ((group['datetime'].max() - group['datetime'].min()).total_seconds() / 3600),\n",
    "        'morning_activity': morning,\n",
    "        'afternoon_activity': afternoon,\n",
    "        'evening_activity': evening,\n",
    "        'night_activity': night\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b64a5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the feature engineering function \n",
    "motion_features = motion_df.groupby('home_id').apply(create_features).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9937926e",
   "metadata": {},
   "source": [
    "# 4. Merging DataFrames and Handling Missing Values\n",
    "\n",
    "Merging the homes data with the newly created motion features and handle any missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d12334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging homes and motion features\n",
    "merged_df = homes_df.merge(motion_features, left_on='id', right_on='home_id', how='left')\n",
    "\n",
    "# Filling NaN values (homes with no motion data) with 0\n",
    "merged_df = merged_df.fillna(0)\n",
    "\n",
    "# Prepared features and target\n",
    "X = merged_df[['motion_count', 'time_range_hours', 'unique_locations', 'activity_hours',\n",
    "               'events_per_hour', 'morning_activity', 'afternoon_activity', 'evening_activity', 'night_activity']]\n",
    "y = merged_df['multiple_occupancy']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da5c31",
   "metadata": {},
   "source": [
    "# 5. Handling Class Imbalance\n",
    "\n",
    "Using SMOTE (Synthetic Minority Over-sampling Technique) to handle class imbalance in the target variable.\n",
    "Train-Test Split method to split the resampled data into training and testing sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19fd849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE for oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "# Spliting the resampled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c3e29c",
   "metadata": {},
   "source": [
    "# 6. Hyperparameter Tuning and Model Training\n",
    "\n",
    "Performing hyperparameter tuning using Randomized Search CV to find the best parameters for our Random Forest model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01699014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03351ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={'max_depth': [None, 10, 20, 30],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 300]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing RandomizedSearchCV\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_grid, n_iter=20, cv=5, random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0857bfa6",
   "metadata": {},
   "source": [
    "# 7. Model Evaluation\n",
    "\n",
    "Evaluating the performance of the best model on the test set and displaying the accuracy and classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53095fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        13\n",
      "           1       1.00      0.42      0.59        12\n",
      "\n",
      "    accuracy                           0.72        25\n",
      "   macro avg       0.82      0.71      0.69        25\n",
      "weighted avg       0.82      0.72      0.69        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the best model\n",
    "best_rf = random_search.best_estimator_\n",
    "# Making predictions\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "# Evaluating the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f280e4f",
   "metadata": {},
   "source": [
    "# 8. Feature Importance\n",
    "\n",
    "Displaying the importance of each feature in the trained Random Forest model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d430c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "              feature  importance\n",
      "0        motion_count    0.167973\n",
      "7    evening_activity    0.161169\n",
      "4     events_per_hour    0.153963\n",
      "6  afternoon_activity    0.127808\n",
      "5    morning_activity    0.112540\n",
      "8      night_activity    0.089866\n",
      "1    time_range_hours    0.087646\n",
      "2    unique_locations    0.079559\n",
      "3      activity_hours    0.019476\n",
      "\n",
      "Best Parameters: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Printing best parameters\n",
    "print(\"\\nBest Parameters:\", random_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
